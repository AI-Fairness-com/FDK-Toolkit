# ğŸŒ FDKâ„¢ Domain Explanations

[![License: Apache-2.0](https://img.shields.io/badge/License-Apache--2.0-green.svg)](https://www.apache.org/licenses/LICENSE-2.0)

This document provides clear explanations of the **seven domains** covered by the Fairness Diagnostic Kit (FDKâ„¢).  
Each domain has its own bias patterns, fairness risks, stakeholder expectations, and metric combinations.  
The content follows the structure and definitions introduced in the *FDKâ„¢ book* (Tavakoli, 2025).

---

## ğŸ§© Overview of Domains

FDKâ„¢ covers fairness diagnostics in:

1. **Business**
2. **Education**
3. **Finance**
4. **Health**
5. **Hiring**
6. **Justice**
7. **Governance**

Each domain uses:
- Domain-specific fairness rationales  
- Tailored metric sets (36â€“56 metrics depending on domain)  
- Narrative summaries written for public-sector and educational use  
- Composite scoring aligned with risk-assessment principles  

---

# 1ï¸âƒ£ Business Domain

## ğŸ“˜ Purpose  
To evaluate fairness in **customer, employee, and corporate decision processes**, such as:

- Customer service outcomes  
- Loan eligibility pre-screens  
- Subscription risk models  
- Product recommendation fairness  
- Corporate compliance scoring  

## ğŸ’¡ Typical Bias Risks  
- Unequal treatment of demographic groups in service outcomes  
- Disparate resolution rates for similar complaints  
- Biased risk assessments for customers with protected characteristics  
- Over- or under-representation of specific groups in fraud flags  

## ğŸ“Š Metrics Used (Representative Subset)  
- Statistical Parity Difference  
- Disparate Impact Ratio  
- TPR / FPR / FNR gaps  
- Calibration error gaps  
- Balanced accuracy difference  
- Group-wise error decomposition  

## ğŸ§© Pipeline Output  
- Composite bias score (0â€“100)  
- Severity: LOW / MEDIUM / HIGH  
- Narrative summary explaining fairness patterns  
- JSON report with complete metric set  

---

# 2ï¸âƒ£ Education Domain

## ğŸ“˜ Purpose  
To assess fairness in:

- Grading algorithms  
- Automated marking  
- Prediction of academic success  
- Admission screening tools  
- School or university risk models  

## ğŸ’¡ Typical Bias Risks  
- Grade inflation/deflation for certain demographic groups  
- Unequal false negative rates (missing capable students)  
- Harmful misclassification in special-needs contexts  
- Region-based or socioeconomic discrimination  

## ğŸ“Š Metrics Used  
- Equal Opportunity Difference  
- FNR Gap (critical for admissions fairness)  
- Demographic Parity metrics  
- Predictive parity differences  
- Group error decomposition  

## ğŸ§© Pipeline Output  
Same structured JSON schema as other domains, with additional emphasis on:

- Misclassification harms  
- Group-wise academic opportunity gaps  

---

# 3ï¸âƒ£ Finance Domain

## ğŸ“˜ Purpose  
To provide fairness diagnostics for:

- Credit approval algorithms  
- Lending risk models  
- Financial inclusion scoring  
- Debt recovery prioritisation  
- Insurance pre-screening  

## ğŸ’¡ Typical Bias Risks  
- Unequal loan approval rates across demographic groups  
- High false positives in high-risk predictions  
- Algorithmic reinforcement of existing financial inequality  
- Region-based stability bias (postcode effect)  

## ğŸ“Š Metrics Used  
- Disparate Impact  
- Approval Rate Ratio  
- Error-rate gaps across groups  
- Calibration-by-group  
- Group-wise ROC metrics  
- Financial inclusion indicators  

## ğŸ§© Pipeline Output  
Financial-domain narrative templates emphasise:

- Fair access  
- Regulatory compliance (FCA expectations)  
- Bias amplification detection  

---

# 4ï¸âƒ£ Health Domain

## ğŸ“˜ Purpose  
To evaluate fairness in:

- Diagnostic risk models  
- Disease prediction tools  
- Clinical triage scoring  
- Patient prioritisation systems  
- Preventive screening models  

## ğŸ’¡ Typical Bias Risks  
- Higher misdiagnosis rates for minority groups  
- Unequal false negatives (critical clinical safety issue)  
- Region-linked disparities in predicted risk  
- Under-representation of disability groups in outcomes  

## ğŸ“Š Metrics Used  
- False Negative Rate Gap (core metric in clinical fairness)  
- Equalised Odds  
- Sensitivity / Specificity gaps  
- Calibration errors  
- Predictive value differences  

## ğŸ§© Pipeline Output  
Plain-language summary emphasises:

- Clinical risk  
- Safety implications  
- Potential harm severity  

---

# 5ï¸âƒ£ Hiring Domain

## ğŸ“˜ Purpose  
To evaluate fairness in:

- Resume screening algorithms  
- Promotion scoring  
- Shortlisting tools  
- Automated assessment outcomes  

## ğŸ’¡ Typical Bias Risks  
- Disparate rejection rates  
- Over-penalising employment gaps for some groups  
- Gender-based false negatives  
- Algorithmic overreliance on proxy attributes  

## ğŸ“Š Metrics Used  
- Statistical Parity  
- Selection Rate Ratio  
- TPR / FNR gaps  
- Adverse Impact Ratio (commonly used in HR contexts)  
- Group-wise confusion matrix decomposition  

## ğŸ§© Pipeline Output  
The narrative emphasises:

- Hiring transparency  
- Diversity impact  
- Group-level selection disparities  

---

# 6ï¸âƒ£ Justice Domain

## ğŸ“˜ Purpose  
To evaluate fairness in:

- Automated recidivism scoring  
- Risk assessment tools  
- Sentencing recommendations  
- Pre-trial decision algorithms  

## ğŸ’¡ Typical Bias Risks  
- Overprediction of risk for minority groups  
- FNR gaps that create unequal incarceration patterns  
- Statistical bias due to historical policing inequalities  
- Unequal calibration across groups  

## ğŸ“Š Metrics Used  
- FPR gap / FNR gap (critical metrics in justice fairness)  
- Balanced accuracy differences  
- Predictive parity  
- Calibration error  
- Group-wise risk distribution divergence  

## ğŸ§© Pipeline Output  
Narrative emphasises:

- Ethical and legal implications  
- Known sensitivity of justice domain fairness  
- Proportionality and equal treatment  

---

# 7ï¸âƒ£ Governance Domain

## ğŸ“˜ Purpose  
To evaluate fairness in:

- Public-sector resource allocation models  
- Policy analytics tools  
- Eligibility scoring for government programs  
- Social support triage  

## ğŸ’¡ Typical Bias Risks  
- Unequal eligibility predictions  
- Region-based misclassification  
- Age-linked fairness failures  
- Socioeconomic segregation effects  

## ğŸ“Š Metrics Used  
- Statistical parity metrics  
- Resource allocation disparities  
- Composite inclusion indicators  
- Region-wise risk differences  

## ğŸ§© Pipeline Output  
Narrative emphasises:

- Public-sector transparency  
- Equality-of-access principles  
- Policy fairness implications  

---

# ğŸ§­ Cross-Domain Consistency

All domains share:

- Identical input schema expectations  
- The same JSON output structure  
- The same upload â†’ detect â†’ confirm â†’ run â†’ download workflow  
- Domain-specific fairness metrics (unique sets based on typical harms)  
- A standardised composite scoring system  
- Plain-language summaries aligned with the FDKâ„¢ book  

This enables users to run fairness diagnostics across multiple sectors while maintaining interpretability and consistency.

---

# ğŸ“¬ Contact

For domain-specific questions or academic collaboration:

```text
info@ai-fairness.com
