# üß™ FDK‚Ñ¢ Example Usage Guide

[![License: Apache-2.0](https://img.shields.io/badge/License-Apache--2.0-green.svg)](https://www.apache.org/licenses/LICENSE-2.0)

This guide provides clear, practical examples of how to use each FDK‚Ñ¢ domain interface.  
The examples follow the upload ‚Üí auto-confirm ‚Üí fairness audit ‚Üí JSON report workflow used across all seven domains.

---

## üåç Overview

Every FDK‚Ñ¢ domain follows the same operational pattern:

1. Upload a **de-identified CSV dataset**
2. FDK‚Ñ¢ automatically detects:
   - Sensitive group attributes  
   - Outcome (`y_true`)  
   - Model predictions (`y_pred`)  
   - Optional probability scores (`y_prob`)
3. User confirms or adjusts detected mappings
4. Domain-specific fairness metrics are calculated
5. A human-readable summary and detailed JSON report are generated

This document demonstrates these steps using example datasets.

---

## üöÄ Jupyter Notebook Demo - Justice Domain

### üìì Interactive Tutorial Now Available

Access our comprehensive Justice domain demo:

```bash
demos/FDK_Justice_Demo.ipynb
üéØ Demo Features:
Complete Justice pipeline execution (36 metrics)

COMPAS-like dataset analysis

Interactive visualizations

Legal compliance assessment

Exportable audit reports

üî¨ Sample Results:
Statistical Parity Difference: 0.165

Disparate Impact Ratio: 0.734

Composite Bias Score: 0.1793

Severity: HIGH_BIAS

üìä Real Dataset Integration
Justice Domain with COMPAS Dataset
python
# Load and analyze real COMPAS dataset
from Justice.compas_loader import load_compas_data
from fdk_justice_pipeline import run_pipeline

# Load real COMPAS data (6,172 samples)
df = load_compas_data()

# Run comprehensive fairness audit
results = run_pipeline(df)

print(f"Composite Bias Score: {results['summary']['composite_bias_score']:.4f}")
print(f"Assessment: {results['summary']['overall_assessment']}")
Dataset Information
COMPAS Dataset: 6,172 real-world recidivism risk assessment records

Source: ProPublica COMPAS Analysis

Use Case: Justice domain fairness validation

Features: Demographic groups, true outcomes, model predictions

Jupyter Demo
Access the complete analysis in: demos/FDK_Justice_Demo.ipynb

The demo includes:

Real COMPAS dataset loading and preprocessing

36 justice-specific fairness metrics

Interactive visualizations

Legal compliance assessment

Exportable audit reports

1Ô∏è‚É£ Business Domain ‚Äî Example Workflow
üìÅ Uploading the dataset
Navigate to:

/business-upload

Upload a CSV file with columns such as:

Gender

Ethnicity

CustomerServiceOutcome

ModelPrediction

ProbabilityScore

FDK‚Ñ¢ automatically detects appropriate mappings.

üîç Auto-Confirmed Mappings
The system displays:

Group attributes: Gender, Ethnicity

Outcome column: CustomerServiceOutcome

Prediction column: ModelPrediction

Probability column (optional): ProbabilityScore

You may adjust these if needed.

‚ñ∂Ô∏è Running the Fairness Audit
Select "Run Fairness Audit".
The Business pipeline calculates fairness metrics, including:

Statistical Parity Difference

Disparate Impact Ratio

TPR / FPR / FNR gaps

Calibration differences

Balanced accuracy differences

üìÑ Example JSON Output (Excerpt)
json
{
  "domain": "Business",
  "severity": "MEDIUM",
  "composite_bias_score": 62.5,
  "fairness_metrics": {
    "statistical_parity_difference": -0.18,
    "disparate_impact": 0.77,
    "fpr_gap": 0.05,
    "fnr_gap": 0.12
  },
  "summary": "Group A is experiencing lower service outcomes..."
}
üß† Human-Readable Summary
FDK‚Ñ¢ also generates a narrative overview explaining:

Key disparities

Groups most affected

Direction of bias

Summary of potential risks

Contextual interpretation based on the Business domain

2Ô∏è‚É£ Education Domain ‚Äî Example Workflow
üìÅ Upload
Go to:

/education-upload

Upload a dataset containing:

Demographics (e.g., Ethnicity, Gender, Region)

FinalGrade or PassFail

PredictedGrade

üîç Auto-Confirm
FDK‚Ñ¢ detects:

Sensitive attributes

Ground truth (y_true)

Prediction (y_pred)

‚ñ∂Ô∏è Run Audit
Key Education-specific metrics include:

Equal Opportunity Difference

FNR Gap (critical in admissions fairness)

Calibration gaps

Prediction parity differences

Group error decomposition

3Ô∏è‚É£ Finance Domain ‚Äî Example Workflow
Upload via:

/finance-upload

Dataset example columns:

AgeBand

Ethnicity

CreditOutcome

PredictedApproval

ProbabilityScore

Metrics computed include:

Disparate Impact

Approval Rate Ratio

Error rate gaps

Calibration-by-group

4Ô∏è‚É£ Health Domain ‚Äî Example Workflow
Upload via:

/health-upload

Dataset should include:

Demographic attributes

Clinical ground truth (e.g., diagnosis)

Model prediction

Optional risk probability

Metrics highlight:

FNR Gap (critical in clinical safety)

Equalised Odds

Sensitivity / Specificity gaps

Predictive value differences

Narrative summary focuses on healthcare risk implications.

5Ô∏è‚É£ Hiring Domain ‚Äî Example Workflow
Upload via:

/hiring-upload

Dataset may include:

Candidate demographic fields

Shortlisted (true outcome)

ModelShortlistPrediction

Metrics include:

Adverse Impact Ratio

TPR / FNR gaps

Selection Rate Ratio

Statistical Parity

Narrative focuses on employment transparency and diversity impact.

6Ô∏è‚É£ Justice Domain ‚Äî Example Workflow
Upload via:

/justice-upload

Dataset may include:

Region, Ethnicity, AgeBand

JusticeOutcome (0/1)

PredictedRisk

Probability score

Metrics include:

FPR / FNR Gap

Predictive parity

Calibration error

Balanced accuracy difference

Narrative emphasises legal fairness concerns.

7Ô∏è‚É£ Governance Domain ‚Äî Example Workflow
Upload via:

/governance-upload

Dataset example columns:

Demographic attributes

Eligibility or resource decision outcome

Model prediction

Optional scoring probability

Metrics include:

Statistical parity

Resource allocation disparities

Region-wise inclusion indicators

Narrative focuses on public-sector transparency and equality of access.

üéØ Key Takeaways
Across all domains:

The workflow is identical for user simplicity

The metrics differ based on domain fairness risks

The JSON output follows a shared schema

Narrative summaries help non-technical users interpret fairness results

Composite scoring standardises fairness evaluation across sectors

üì¨ Contact
For demonstration datasets, academic usage, or domain-specific questions:

info@ai-fairness.com
